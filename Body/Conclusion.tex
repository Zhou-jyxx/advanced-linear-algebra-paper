\section{总结}

本文对于最优化问题分析并总结了多种求解方法，
包括在无约束条件下的梯度下降法，随机梯度法，临近梯度法，牛顿迭代法，拟牛顿迭代法，共轭梯度法等；
以及在有约束条件下的增广拉格朗日乘子法与交替方向乘子法。
以下分别概括几类最优化方法的特点：\\

\textbf{1) 梯度下降法}

梯度下降法是一类非常基础的方法，
其基本思想是根据步长和当前位置计算梯度，
到达下一个迭代点。
由于每次学习都使用整个函数，
所以最终能保证收敛于极值点，
凸函数收敛于全局极值点，
非凸函数可能收敛于局部极值点，
而全局的使用导致这种方法学习时间过长，消耗资源。\\


\textbf{2) 随机梯度法}

随机梯度下降是梯度下降法的一种求解思路，
其可以被用于解决梯度下降法的弊端，
在随机梯度下降法中，
每次迭代可以只用一个训练数据来更新参数。
相较于一般梯度下降法，其训练速度快，
但代价是准确度下降、不是全局最优、不易于并行实现
随机梯度下降会最小化所有训练样本的损失函数，
使得最终解为全局最优解，即求解参数会使得风险函数最小；
虽不是每次迭代得到的损失函数都向着全局最优方向，
但整体方向是全局最优解，
且最终结果往往在全局最优解附近。\\


\textbf{3) 临近梯度法}

临近梯度法是一种特殊的梯度下降方法，
主要用于求解目标函数不可微的最优化问题。
如果目标函数在某些点是不可微的，
那么该点的梯度无法求解，
传统的梯度下降法也就无法使用。
该算法的思想是，使用临近算子作为近似梯度，进行梯度下降。
其收敛性结果同梯度下降法一致，但是收敛速度在实际中略小于梯度下降法\\

\textbf{4) 牛顿迭代法}

牛顿法收敛很快，
对于二次函数只迭代一次便达到最优点，
对于二次函数也能较快迭代到最优点，
但要计算二阶偏导数矩阵及其逆矩阵,
对维数较高的优化问题,
其计算工作和存储量都太大。\\


\textbf{5) 拟牛顿迭代法}

拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hesse矩阵的逆矩阵的缺陷，
它使用正定矩阵来近似Hesse矩阵的逆，
从而简化了运算的复杂度；
而且有时候目标函数的Hesse矩阵无法保证正定。
拟牛顿法只要求每一步迭代时知道目标函数的梯度,通过测量梯度的变化，
构造一个目标函数的模型使之足以产生超线性收敛性。
另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。
如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。
常用的拟牛顿法有DFP算法和BFGS算法。\\

\textbf{6) 共轭梯度法}

共轭梯度法是介于梯度下降法与牛顿法之间的一个方法，
它仅需利用一阶导数信息，
但克服了梯度下降法收敛慢的缺点，
又避免了牛顿法需要存储和计算Hesse矩阵并求逆的缺点，
共轭梯度法不仅是解决大型线性方程组最有用的方法之一，
也是解大型非线性最优化最有效的算法之一。
在各种优化算法中，
共轭梯度法是非常重要的一种。
其优点是所需存储量小，具有步收敛性，
稳定性高，而且不需要任何外来参数。\\

\textbf{7) 增广拉格朗日乘子法}

增广拉格朗日方法在传统拉格朗日方法的基础上，
针对函数对应的拉格朗日函数添加罚项。
只要函数的约束条件不满足，
就会根据它脱轨的情况来做一定的惩罚，
这样做可以把一个带约束优化的问题重新变回了无约束优化问题。\\

\textbf{8) 交替方向乘子法}

交替方向乘子法是为了解决增广拉格朗日算法不能做分解的问题。
它考虑了自变量由两个部分组合而成时候如何分解优化的问题。
其大致思想是是交替地根据某一个变量求最值，同时固定住其余变量。
如此可以把原本可能不凸问题变成凸问题。\\